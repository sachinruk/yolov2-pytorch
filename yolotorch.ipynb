{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!apt-get update && apt-get install -y libsm6 libxext6 libxrender-dev\n",
    "!pip install opencv-contrib-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import pandas as pd\n",
    "import struct, os\n",
    "import re, numpy as np\n",
    "# from skimage import transform\n",
    "import itertools, operator\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import xml.etree.ElementTree as ET\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Yolo v2 config\n",
    "# Load pre-trained weights from darknet 23 layer\n",
    "# Understand the Yolo v2 training process \n",
    "#            - Data Aug\n",
    "#            - Multi Scale Training\n",
    "#            - Loss Fn\n",
    "#            - Learning Rate\n",
    "#            - Optimizer setting\n",
    "# \n",
    "# Understand how the model requires <input, labels> feed dict\n",
    "# Read PASCAL data in the format needed\n",
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Augmentation\n",
    "# Transforms classes\n",
    "# Random scale\n",
    "# Flip\n",
    "# x, y reposition\n",
    "class RandomCrop(object):\n",
    "    \n",
    "    def imcv2_affine_trans(self, im):\n",
    "        # Scale and translate\n",
    "        h, w, c = im.shape\n",
    "        scale = np.random.uniform() / 10. + 1.\n",
    "        max_offx = (scale-1.) * w\n",
    "        max_offy = (scale-1.) * h\n",
    "        offx = int(np.random.uniform() * max_offx)\n",
    "        offy = int(np.random.uniform() * max_offy)\n",
    "\n",
    "        im = cv2.resize(im, (0,0), fx = scale, fy = scale)\n",
    "        im = im[offy : (offy + h), offx : (offx + w)]\n",
    "\n",
    "        return im, [w, h], [scale, [offx, offy]]\n",
    "\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, bboxes = sample['image'], sample['bboxes']\n",
    "        result = self.imcv2_affine_trans(image)\n",
    "        image, dims, trans_param = result\n",
    "        scale, offs = trans_param\n",
    "        \n",
    "        offs = np.array(offs*2)\n",
    "        dims = np.array(dims*2)\n",
    "        bboxes = deepcopy(bboxes)\n",
    "        bboxes[:, 1:] = np.array(bboxes[:, 1:]*scale - offs, np.int64)\n",
    "        bboxes[:, 1:] = np.maximum(np.minimum(bboxes[:, 1:], dims), 0)\n",
    "        \n",
    "        check_errors = (((bboxes[:, 1] >= bboxes[:, 3]) | (bboxes[:, 2] >= bboxes[:, 4])) & (bboxes[:, 0]!=-1))\n",
    "        if sum(check_errors) > 0:\n",
    "            bool_mask = ~ check_errors\n",
    "            bboxes = bboxes[bool_mask]\n",
    "        return {\"image\": image, \"bboxes\": bboxes}\n",
    "\n",
    "class RandomFlip(object):\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, bboxes = sample['image'], sample['bboxes']\n",
    "\n",
    "        bboxes = deepcopy(bboxes)\n",
    "        flip = np.random.binomial(1, .5)\n",
    "        if flip: \n",
    "            w = image.shape[1]\n",
    "            image = cv2.flip(image, 1)\n",
    "            backup_min = deepcopy(bboxes[:, 1])\n",
    "            bboxes[:, 1] = w - bboxes[:, 3]\n",
    "            bboxes[:, 3] = w - backup_min\n",
    "        \n",
    "        if sum(((bboxes[:, 1] >= bboxes[:, 3]) | (bboxes[:, 2] >= bboxes[:, 4])) & (bboxes[:, 0]!=-1)) > 0:\n",
    "            print (\"random flip\")\n",
    "        \n",
    "        return {\"image\": image, \"bboxes\": bboxes}\n",
    "\n",
    "class Rescale(object):\n",
    "    \n",
    "    def __init__(self, output):\n",
    "        self.new_h, self.new_w = output\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        image, bboxes = sample['image'], sample['bboxes']\n",
    "        h, w, c = image.shape\n",
    "        new_h = int(self.new_h)\n",
    "        new_w = int(self.new_w)\n",
    "        image = cv2.resize(image, (new_w, new_h))\n",
    "        \n",
    "        bboxes = deepcopy(bboxes)\n",
    "        bboxes = np.array(bboxes, np.float64)\n",
    "        bboxes[:, 1] *= new_w*1.0/w\n",
    "        bboxes[:, 2] *= new_h*1.0/h\n",
    "        bboxes[:, 3] *= new_w*1.0/w\n",
    "        bboxes[:, 4] *= new_h*1.0/h\n",
    "        if sum(((bboxes[:, 1] >= bboxes[:, 3]) | (bboxes[:, 2] >= bboxes[:, 4])) & (bboxes[:, 0]!=-1)) > 0:\n",
    "            print (\"random scale\", bboxes, sample['bboxes'], new_w, new_h, w, h)\n",
    "\n",
    "        return {\"image\": image, \"bboxes\": bboxes}\n",
    "\n",
    "class TransformBoxCoords(object):\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, bboxes = sample['image'], sample['bboxes']\n",
    "        height, width, _ = image.shape\n",
    "        \n",
    "        bboxes = deepcopy(bboxes)\n",
    "        bboxes = np.array(bboxes, np.float64)\n",
    "        x = 0.5 * (bboxes[:, 1] + bboxes[:, 3])\n",
    "        y = 0.5 * (bboxes[:, 2] + bboxes[:, 4])\n",
    "        w = 1. * (bboxes[:, 3] - bboxes[:, 1])\n",
    "        h = 1. * (bboxes[:, 4] - bboxes[:, 2])\n",
    "        if sum(((w <= 0) | (h <= 0) | (x <= 0) | (y <= 0)) & (bboxes[:, 0]!=-1))>0:\n",
    "            print (\"up\", bboxes, sample[\"bboxes\"])\n",
    "        bboxes[:, 1] = x/width\n",
    "        bboxes[:, 2] = y/height\n",
    "        bboxes[:, 3] = w/width\n",
    "        bboxes[:, 4] = h/height\n",
    "        if sum(((bboxes[:, 1] <0) | (bboxes[:, 2]<0) | (bboxes[:, 3]<=0) | (bboxes[:, 4]<=0)) & (bboxes[:, 0]!=-1)) > 0:\n",
    "            print (\"random transform box coords\")\n",
    "\n",
    "        \n",
    "        return {\"image\": image, \"bboxes\": bboxes}\n",
    "\n",
    "class Normalize(object):\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        image, bboxes = sample['image'], sample['bboxes']\n",
    "        image = np.array(image, np.float64)\n",
    "        image /= 255.0\n",
    "        return {\"image\": image, \"bboxes\": bboxes}\n",
    "\n",
    "class EliminateSmallBoxes(object):\n",
    "    \n",
    "    def __init__(self, thresh):\n",
    "        self.thresh = thresh\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, bboxes = sample['image'], sample['bboxes']\n",
    "        bool_mask = ((bboxes[: , 3] > self.thresh) & (bboxes[: , 4] > self.thresh))\n",
    "        bboxes = bboxes[bool_mask]\n",
    "        return {\"image\": image, \"bboxes\": bboxes}\n",
    "\n",
    "\n",
    "class ToTensor(object):\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, bboxes = sample['image'], sample['bboxes']\n",
    "\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C X H X W\n",
    "#         image = image.transpose((2, 0, 1))\n",
    "        if len(bboxes) == 0:\n",
    "            return {'image': torch.from_numpy(image), 'bboxes': torch.DoubleTensor()}\n",
    "        return {'image': torch.from_numpy(image), 'bboxes': torch.from_numpy(bboxes)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes =  np.array(['sheep', 'horse', 'bicycle', 'bottle', 'cow', 'sofa', 'car', 'dog', 'cat', 'person', 'train', 'diningtable', 'aeroplane', 'bus', 'pottedplant', 'tvmonitor', 'chair', 'bird', 'boat', 'motorbike'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./data/test/VOCdevkit/VOC2012/'"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_loader.dataset.folderpath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = glob.glob('./data/test/VOCdevkit/VOC2012/'+\"/JPEGImages/*.jpg\")\n",
    "imagenames = [re.split(\"\\\\.\", re.split(\"\\\\/\", names[i])[-1])[0] for i in range(len(names))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2008_008699',\n",
       " '2010_004633',\n",
       " '2008_004211',\n",
       " '2008_003555',\n",
       " '2008_004294',\n",
       " '2012_003471',\n",
       " '2008_005030',\n",
       " '2009_002095',\n",
       " '2012_002039',\n",
       " '2011_003840',\n",
       " '2008_006905',\n",
       " '2011_001494',\n",
       " '2010_004736',\n",
       " '2011_003248',\n",
       " '2012_002680',\n",
       " '2012_002231',\n",
       " '2009_004549',\n",
       " '2009_001459',\n",
       " '2011_001478',\n",
       " '2012_003312',\n",
       " '2012_001936',\n",
       " '2012_004128',\n",
       " '2008_000344',\n",
       " '2011_001379',\n",
       " '2008_006165',\n",
       " '2009_002786',\n",
       " '2011_004608',\n",
       " '2010_000835',\n",
       " '2012_000685',\n",
       " '2009_005277',\n",
       " '2008_004405',\n",
       " '2008_004650',\n",
       " '2011_005279',\n",
       " '2011_003835',\n",
       " '2012_001574',\n",
       " '2012_001464',\n",
       " '2009_001923',\n",
       " '2011_005350',\n",
       " '2009_001766',\n",
       " '2011_000367',\n",
       " '2008_006266',\n",
       " '2008_005326',\n",
       " '2009_004636',\n",
       " '2011_001985',\n",
       " '2010_004134',\n",
       " '2009_002810',\n",
       " '2011_000697',\n",
       " '2010_005994',\n",
       " '2012_001751',\n",
       " '2010_002013',\n",
       " '2011_007147',\n",
       " '2011_006711',\n",
       " '2008_003649',\n",
       " '2010_001389',\n",
       " '2009_003332',\n",
       " '2011_006791',\n",
       " '2009_002132',\n",
       " '2010_000115',\n",
       " '2010_000126',\n",
       " '2008_006757',\n",
       " '2009_005029',\n",
       " '2008_005506',\n",
       " '2008_008264',\n",
       " '2008_006894',\n",
       " '2009_000076',\n",
       " '2009_002930',\n",
       " '2010_002530',\n",
       " '2009_003834',\n",
       " '2011_003649',\n",
       " '2011_001121',\n",
       " '2010_002323',\n",
       " '2010_002957',\n",
       " '2011_002320',\n",
       " '2011_006035',\n",
       " '2008_006278',\n",
       " '2008_005981',\n",
       " '2008_003011',\n",
       " '2011_006131',\n",
       " '2011_004429',\n",
       " '2010_001996',\n",
       " '2011_004965',\n",
       " '2010_006901',\n",
       " '2011_006085',\n",
       " '2012_000945',\n",
       " '2009_004354',\n",
       " '2009_003631',\n",
       " '2008_001884',\n",
       " '2011_004466',\n",
       " '2012_000352',\n",
       " '2010_000551',\n",
       " '2010_001725',\n",
       " '2011_002635',\n",
       " '2011_005083',\n",
       " '2008_004836',\n",
       " '2011_006349',\n",
       " '2009_004884',\n",
       " '2012_001508',\n",
       " '2010_004915',\n",
       " '2012_000720',\n",
       " '2010_000185',\n",
       " '2008_002722',\n",
       " '2008_001001',\n",
       " '2008_005670',\n",
       " '2012_002422',\n",
       " '2008_007778',\n",
       " '2010_000146',\n",
       " '2010_003294',\n",
       " '2008_002585',\n",
       " '2009_004296',\n",
       " '2011_004793',\n",
       " '2012_001441',\n",
       " '2011_000356',\n",
       " '2010_005485',\n",
       " '2010_000757',\n",
       " '2009_003749',\n",
       " '2011_005955',\n",
       " '2011_003587',\n",
       " '2012_001534',\n",
       " '2008_007562',\n",
       " '2008_005077',\n",
       " '2010_001667',\n",
       " '2012_002626',\n",
       " '2009_001596',\n",
       " '2012_003666',\n",
       " '2010_006610',\n",
       " '2008_007856',\n",
       " '2008_002051',\n",
       " '2008_007436',\n",
       " '2008_005311',\n",
       " '2010_001920',\n",
       " '2008_000456',\n",
       " '2012_003858',\n",
       " '2010_002874',\n",
       " '2012_003169',\n",
       " '2011_002801',\n",
       " '2010_003110',\n",
       " '2009_004788',\n",
       " '2010_003163',\n",
       " '2012_000988',\n",
       " '2011_000001',\n",
       " '2012_004305',\n",
       " '2008_008213',\n",
       " '2012_001722',\n",
       " '2010_001855',\n",
       " '2008_003357',\n",
       " '2011_005682',\n",
       " '2008_001581',\n",
       " '2008_008741',\n",
       " '2008_005539',\n",
       " '2009_004120',\n",
       " '2012_002347',\n",
       " '2009_004331',\n",
       " '2011_006552',\n",
       " '2008_005424',\n",
       " '2009_002034',\n",
       " '2010_004652',\n",
       " '2011_000123',\n",
       " '2008_006770',\n",
       " '2008_002683',\n",
       " '2008_004609',\n",
       " '2010_006641',\n",
       " '2011_000199',\n",
       " '2008_006367',\n",
       " '2009_003676',\n",
       " '2008_000772',\n",
       " '2008_004918',\n",
       " '2011_003936',\n",
       " '2010_003923',\n",
       " '2012_001812',\n",
       " '2010_004302',\n",
       " '2012_001980',\n",
       " '2011_005274',\n",
       " '2008_007027',\n",
       " '2008_007920',\n",
       " '2010_006107',\n",
       " '2009_004989',\n",
       " '2010_006002',\n",
       " '2009_002742',\n",
       " '2011_002874',\n",
       " '2009_004757',\n",
       " '2008_001637',\n",
       " '2010_001314',\n",
       " '2011_004366',\n",
       " '2008_001269',\n",
       " '2008_002858',\n",
       " '2010_001597',\n",
       " '2011_000956',\n",
       " '2009_004773',\n",
       " '2011_004010',\n",
       " '2012_002769',\n",
       " '2010_002846',\n",
       " '2012_002532',\n",
       " '2008_004272',\n",
       " '2011_004650',\n",
       " '2009_005280',\n",
       " '2008_000165',\n",
       " '2010_001392',\n",
       " '2009_003318',\n",
       " '2010_006755',\n",
       " '2011_001798',\n",
       " '2008_003699',\n",
       " '2009_004408',\n",
       " '2008_002166',\n",
       " '2011_001630',\n",
       " '2010_000339',\n",
       " '2010_006188',\n",
       " '2010_006374',\n",
       " '2009_001185',\n",
       " '2011_002680',\n",
       " '2011_002259',\n",
       " '2010_001093',\n",
       " '2012_003061',\n",
       " '2012_000208',\n",
       " '2009_002303',\n",
       " '2008_001058',\n",
       " '2010_004465',\n",
       " '2009_001342',\n",
       " '2011_003916',\n",
       " '2008_000299',\n",
       " '2010_002619',\n",
       " '2012_003599',\n",
       " '2011_006286',\n",
       " '2008_001458',\n",
       " '2009_001717',\n",
       " '2009_004155',\n",
       " '2010_006460',\n",
       " '2008_004601',\n",
       " '2011_001426',\n",
       " '2010_001498',\n",
       " '2011_005891',\n",
       " '2011_002991',\n",
       " '2010_002835',\n",
       " '2008_003895',\n",
       " '2010_003284',\n",
       " '2010_006151',\n",
       " '2008_005581',\n",
       " '2010_000668',\n",
       " '2010_002617',\n",
       " '2012_003266',\n",
       " '2009_005243',\n",
       " '2008_006688',\n",
       " '2008_007731',\n",
       " '2011_005234',\n",
       " '2008_006539',\n",
       " '2009_003670',\n",
       " '2009_002987',\n",
       " '2010_004612',\n",
       " '2012_003236',\n",
       " '2010_001474',\n",
       " '2011_006369',\n",
       " '2009_002032',\n",
       " '2011_001459',\n",
       " '2009_001340',\n",
       " '2011_002087',\n",
       " '2008_008062',\n",
       " '2010_006419',\n",
       " '2009_002218',\n",
       " '2009_005285',\n",
       " '2011_004475',\n",
       " '2008_001412',\n",
       " '2011_003004',\n",
       " '2008_001933',\n",
       " '2008_007387',\n",
       " '2008_002819',\n",
       " '2011_006931',\n",
       " '2010_001600',\n",
       " '2012_001066',\n",
       " '2008_005289',\n",
       " '2012_004271',\n",
       " '2011_000451',\n",
       " '2008_002391',\n",
       " '2008_001093',\n",
       " '2008_004780',\n",
       " '2009_004235',\n",
       " '2010_003172',\n",
       " '2008_000823',\n",
       " '2010_001848',\n",
       " '2009_002773',\n",
       " '2011_001639',\n",
       " '2011_002891',\n",
       " '2010_002863',\n",
       " '2009_004344',\n",
       " '2011_001960',\n",
       " '2011_006431',\n",
       " '2010_000555',\n",
       " '2010_003360',\n",
       " '2011_002593',\n",
       " '2008_002593',\n",
       " '2010_004796',\n",
       " '2008_004798',\n",
       " '2010_002757',\n",
       " '2009_002186',\n",
       " '2009_002479',\n",
       " '2008_008067',\n",
       " '2011_004716',\n",
       " '2008_003324',\n",
       " '2011_001250',\n",
       " '2008_006479',\n",
       " '2011_006269',\n",
       " '2011_001289',\n",
       " '2010_000763',\n",
       " '2011_003233',\n",
       " '2011_003282',\n",
       " '2011_006949',\n",
       " '2008_004468',\n",
       " '2011_000478',\n",
       " '2012_000111',\n",
       " '2009_000095',\n",
       " '2009_003192',\n",
       " '2012_000342',\n",
       " '2012_000437',\n",
       " '2009_004842',\n",
       " '2010_001442',\n",
       " '2010_002066',\n",
       " '2011_005014',\n",
       " '2012_003574',\n",
       " '2009_002347',\n",
       " '2010_002476',\n",
       " '2009_000374',\n",
       " '2009_005077',\n",
       " '2010_000445',\n",
       " '2009_002383',\n",
       " '2011_005366',\n",
       " '2012_000406',\n",
       " '2012_001544',\n",
       " '2008_006812',\n",
       " '2009_002454',\n",
       " '2012_003929',\n",
       " '2010_002700',\n",
       " '2008_001364',\n",
       " '2008_001898',\n",
       " '2008_008644',\n",
       " '2008_003935',\n",
       " '2008_002832',\n",
       " '2008_001396',\n",
       " '2008_005278',\n",
       " '2008_001988',\n",
       " '2011_000980',\n",
       " '2011_004121',\n",
       " '2011_007200',\n",
       " '2009_000373',\n",
       " '2012_001994',\n",
       " '2010_002381',\n",
       " '2012_001780',\n",
       " '2010_004882',\n",
       " '2012_000735',\n",
       " '2012_004217',\n",
       " '2010_001332',\n",
       " '2008_000497',\n",
       " '2008_002669',\n",
       " '2008_006571',\n",
       " '2011_005821',\n",
       " '2011_004125',\n",
       " '2009_002653',\n",
       " '2008_000757',\n",
       " '2010_003646',\n",
       " '2008_006469',\n",
       " '2010_001616',\n",
       " '2011_003129',\n",
       " '2009_004239',\n",
       " '2009_001655',\n",
       " '2011_004024',\n",
       " '2010_006785',\n",
       " '2011_005405',\n",
       " '2008_002122',\n",
       " '2008_002468',\n",
       " '2012_003423',\n",
       " '2008_007290',\n",
       " '2008_007792',\n",
       " '2009_001220',\n",
       " '2008_006396',\n",
       " '2010_005550',\n",
       " '2012_000143',\n",
       " '2008_006201',\n",
       " '2008_004409',\n",
       " '2010_005102',\n",
       " '2008_001365',\n",
       " '2010_000402',\n",
       " '2008_005948',\n",
       " '2009_003357',\n",
       " '2011_005538',\n",
       " '2012_000424',\n",
       " '2011_005434',\n",
       " '2012_002505',\n",
       " '2008_000324',\n",
       " '2009_005139',\n",
       " '2009_000148',\n",
       " '2010_005397',\n",
       " '2008_001654',\n",
       " '2008_007740',\n",
       " '2010_000892',\n",
       " '2011_000110',\n",
       " '2011_000350',\n",
       " '2010_004384',\n",
       " '2011_002056',\n",
       " '2008_007263',\n",
       " '2008_004925',\n",
       " '2011_006312',\n",
       " '2008_003795',\n",
       " '2010_005105',\n",
       " '2012_000097',\n",
       " '2012_000447',\n",
       " '2011_003371',\n",
       " '2012_002193',\n",
       " '2008_004527',\n",
       " '2008_007772',\n",
       " '2012_002794',\n",
       " '2009_003121',\n",
       " '2008_002554',\n",
       " '2012_003119',\n",
       " '2012_000679',\n",
       " '2011_003635',\n",
       " '2012_001880',\n",
       " '2012_004280',\n",
       " '2012_000236',\n",
       " '2011_005092',\n",
       " '2009_005003',\n",
       " '2010_002074',\n",
       " '2011_000302',\n",
       " '2009_004512',\n",
       " '2008_000388',\n",
       " '2012_003647',\n",
       " '2009_000007',\n",
       " '2009_004387',\n",
       " '2010_001861',\n",
       " '2010_005947',\n",
       " '2011_003877',\n",
       " '2011_005115',\n",
       " '2011_001943',\n",
       " '2010_002869',\n",
       " '2012_004187',\n",
       " '2010_002730',\n",
       " '2010_006671',\n",
       " '2011_003864',\n",
       " '2008_003570',\n",
       " '2010_000816',\n",
       " '2009_001624',\n",
       " '2012_003105',\n",
       " '2009_003061',\n",
       " '2008_005034',\n",
       " '2009_004367',\n",
       " '2009_003755',\n",
       " '2009_002392',\n",
       " '2011_001993',\n",
       " '2011_001413',\n",
       " '2010_003819',\n",
       " '2008_005011',\n",
       " '2008_000751',\n",
       " '2011_001309',\n",
       " '2010_004152',\n",
       " '2010_004266',\n",
       " '2009_004185',\n",
       " '2009_000143',\n",
       " '2009_004612',\n",
       " '2008_005355',\n",
       " '2009_003106',\n",
       " '2009_001099',\n",
       " '2012_001378',\n",
       " '2008_003818',\n",
       " '2011_002010',\n",
       " '2008_001753',\n",
       " '2010_005057',\n",
       " '2010_003328',\n",
       " '2011_004444',\n",
       " '2012_000958',\n",
       " '2010_004810',\n",
       " '2012_001458',\n",
       " '2008_006101',\n",
       " '2010_002591',\n",
       " '2010_002075',\n",
       " '2009_003970',\n",
       " '2008_003715',\n",
       " '2011_006660',\n",
       " '2009_001572',\n",
       " '2012_003904',\n",
       " '2011_006968',\n",
       " '2009_003789',\n",
       " '2012_001908',\n",
       " '2009_004077',\n",
       " '2011_007167',\n",
       " '2010_001658',\n",
       " '2010_003718',\n",
       " '2010_005533',\n",
       " '2010_003431',\n",
       " '2009_003359',\n",
       " '2011_003961',\n",
       " '2010_005395',\n",
       " '2010_004912',\n",
       " '2009_000517',\n",
       " '2012_004237',\n",
       " '2008_006608',\n",
       " '2008_002337',\n",
       " '2011_006243',\n",
       " '2008_002300',\n",
       " '2011_003135',\n",
       " '2008_006043',\n",
       " '2012_002726',\n",
       " '2008_002642',\n",
       " '2011_005294',\n",
       " '2010_005150',\n",
       " '2009_005164',\n",
       " '2012_000634',\n",
       " '2009_003243',\n",
       " '2009_002949',\n",
       " '2009_002639',\n",
       " '2009_002351',\n",
       " '2008_006287',\n",
       " '2012_003012',\n",
       " '2011_001631',\n",
       " '2011_004837',\n",
       " '2012_003235',\n",
       " '2012_002028',\n",
       " '2012_001022',\n",
       " '2009_003342',\n",
       " '2010_002748',\n",
       " '2008_001537',\n",
       " '2011_006083',\n",
       " '2010_005004',\n",
       " '2010_005380',\n",
       " '2008_006745',\n",
       " '2011_004247',\n",
       " '2008_000377',\n",
       " '2010_004939',\n",
       " '2010_000905',\n",
       " '2008_008163',\n",
       " '2011_007129',\n",
       " '2009_004654',\n",
       " '2010_006068',\n",
       " '2008_000680',\n",
       " '2010_003235',\n",
       " '2009_003964',\n",
       " '2008_002163',\n",
       " '2012_003260',\n",
       " '2008_000632',\n",
       " '2010_004552',\n",
       " '2008_000441',\n",
       " '2010_001298',\n",
       " '2009_004932',\n",
       " '2009_002329',\n",
       " '2008_007481',\n",
       " '2009_003515',\n",
       " '2010_004115',\n",
       " '2011_005527',\n",
       " '2012_003087',\n",
       " '2010_005577',\n",
       " '2010_001532',\n",
       " '2009_001020',\n",
       " '2008_001959',\n",
       " '2009_003182',\n",
       " '2008_000013',\n",
       " '2012_001293',\n",
       " '2008_006075',\n",
       " '2009_004810',\n",
       " '2010_001202',\n",
       " '2010_000584',\n",
       " '2008_002291',\n",
       " '2010_003917',\n",
       " '2010_000017',\n",
       " '2012_003381',\n",
       " '2012_000925',\n",
       " '2008_002230',\n",
       " '2008_006976',\n",
       " '2012_003899',\n",
       " '2011_006014',\n",
       " '2009_001244',\n",
       " '2010_005801',\n",
       " '2010_001722',\n",
       " '2012_000470',\n",
       " '2008_006198',\n",
       " '2009_002486',\n",
       " '2008_007294',\n",
       " '2011_006821',\n",
       " '2008_000909',\n",
       " '2008_003714',\n",
       " '2012_003646',\n",
       " '2008_005596',\n",
       " '2011_005704',\n",
       " '2010_002922',\n",
       " '2012_003591',\n",
       " '2008_008657',\n",
       " '2009_002021',\n",
       " '2010_005282',\n",
       " '2011_002800',\n",
       " '2011_001017',\n",
       " '2008_007951',\n",
       " '2008_007614',\n",
       " '2012_003604',\n",
       " '2011_004820',\n",
       " '2010_004233',\n",
       " '2008_000715',\n",
       " '2012_000677',\n",
       " '2009_000717',\n",
       " '2008_003397',\n",
       " '2010_003698',\n",
       " '2011_000313',\n",
       " '2009_004463',\n",
       " '2012_000939',\n",
       " '2008_008390',\n",
       " '2011_000201',\n",
       " '2010_004507',\n",
       " '2009_001947',\n",
       " '2012_003344',\n",
       " '2011_004002',\n",
       " '2011_005981',\n",
       " '2011_006962',\n",
       " '2011_002847',\n",
       " '2012_002994',\n",
       " '2008_005540',\n",
       " '2008_000580',\n",
       " '2011_005824',\n",
       " '2008_001229',\n",
       " '2008_007251',\n",
       " '2008_005206',\n",
       " '2012_000597',\n",
       " '2009_004089',\n",
       " '2012_004278',\n",
       " '2008_006344',\n",
       " '2009_001280',\n",
       " '2008_007530',\n",
       " '2010_006163',\n",
       " '2011_001681',\n",
       " '2012_004197',\n",
       " '2008_005535',\n",
       " '2010_003876',\n",
       " '2008_007385',\n",
       " '2010_003886',\n",
       " '2010_001059',\n",
       " '2009_000784',\n",
       " '2008_006670',\n",
       " '2012_000719',\n",
       " '2011_006067',\n",
       " '2011_001383',\n",
       " '2008_002472',\n",
       " '2012_001698',\n",
       " '2009_004214',\n",
       " '2009_003506',\n",
       " '2008_003727',\n",
       " '2009_001561',\n",
       " '2010_000147',\n",
       " '2008_003243',\n",
       " '2011_001686',\n",
       " '2011_005399',\n",
       " '2011_003821',\n",
       " '2011_004479',\n",
       " '2012_002981',\n",
       " '2008_001398',\n",
       " '2008_006398',\n",
       " '2008_004799',\n",
       " '2012_003219',\n",
       " '2009_001855',\n",
       " '2011_004945',\n",
       " '2009_000230',\n",
       " '2008_007700',\n",
       " '2011_004814',\n",
       " '2011_003394',\n",
       " '2010_003315',\n",
       " '2012_003807',\n",
       " '2010_001581',\n",
       " '2009_004282',\n",
       " '2008_002394',\n",
       " '2010_000482',\n",
       " '2008_005852',\n",
       " '2012_001797',\n",
       " '2011_000877',\n",
       " '2008_007857',\n",
       " '2012_000088',\n",
       " '2009_001351',\n",
       " '2008_007790',\n",
       " '2011_004413',\n",
       " '2008_006515',\n",
       " '2011_001890',\n",
       " '2008_004407',\n",
       " '2008_001096',\n",
       " '2008_001892',\n",
       " '2011_003624',\n",
       " '2012_002174',\n",
       " '2011_005429',\n",
       " '2008_003116',\n",
       " '2008_007769',\n",
       " '2010_003001',\n",
       " '2008_003422',\n",
       " '2008_003438',\n",
       " '2010_000180',\n",
       " '2012_000504',\n",
       " '2012_003495',\n",
       " '2012_001578',\n",
       " '2010_000535',\n",
       " '2008_003294',\n",
       " '2012_001627',\n",
       " '2008_005515',\n",
       " '2009_000905',\n",
       " '2009_005188',\n",
       " '2009_004906',\n",
       " '2011_000493',\n",
       " '2008_006971',\n",
       " '2011_000904',\n",
       " '2009_000255',\n",
       " '2011_000403',\n",
       " '2011_002888',\n",
       " '2012_000061',\n",
       " '2012_003546',\n",
       " '2010_003842',\n",
       " '2011_006946',\n",
       " '2010_000039',\n",
       " '2011_002524',\n",
       " '2010_005988',\n",
       " '2008_002196',\n",
       " '2009_003864',\n",
       " '2011_006483',\n",
       " '2009_003302',\n",
       " '2012_001818',\n",
       " '2012_001128',\n",
       " '2008_006326',\n",
       " '2011_001067',\n",
       " '2008_004049',\n",
       " '2009_001430',\n",
       " '2010_003666',\n",
       " '2010_003033',\n",
       " '2008_001180',\n",
       " '2008_006451',\n",
       " '2008_004577',\n",
       " '2012_000743',\n",
       " '2011_003612',\n",
       " '2008_005545',\n",
       " '2009_004743',\n",
       " '2008_000098',\n",
       " '2011_007102',\n",
       " '2009_002195',\n",
       " '2008_001754',\n",
       " '2009_000033',\n",
       " '2011_003056',\n",
       " '2008_001949',\n",
       " '2012_001206',\n",
       " '2010_005034',\n",
       " '2009_004576',\n",
       " '2010_006752',\n",
       " '2011_000089',\n",
       " '2011_003417',\n",
       " '2010_002523',\n",
       " '2008_001067',\n",
       " '2008_005267',\n",
       " '2009_000510',\n",
       " '2011_004021',\n",
       " '2008_001780',\n",
       " '2009_000929',\n",
       " '2011_003217',\n",
       " '2008_003564',\n",
       " '2008_004639',\n",
       " '2012_001194',\n",
       " '2010_006318',\n",
       " '2008_004117',\n",
       " '2012_002594',\n",
       " '2012_002334',\n",
       " '2008_003832',\n",
       " '2012_000667',\n",
       " '2009_004960',\n",
       " '2011_004153',\n",
       " '2008_005301',\n",
       " '2012_001035',\n",
       " '2011_000726',\n",
       " '2012_002599',\n",
       " '2010_000037',\n",
       " '2008_003938',\n",
       " '2008_006431',\n",
       " '2009_003047',\n",
       " '2009_000700',\n",
       " '2009_001034',\n",
       " '2008_003558',\n",
       " '2012_003745',\n",
       " '2008_002699',\n",
       " '2012_001270',\n",
       " '2010_004497',\n",
       " '2008_002577',\n",
       " '2010_004755',\n",
       " '2008_003605',\n",
       " '2011_001709',\n",
       " '2009_000310',\n",
       " '2008_002530',\n",
       " '2011_000941',\n",
       " '2008_002877',\n",
       " '2011_002408',\n",
       " '2008_001181',\n",
       " '2009_005271',\n",
       " '2008_004580',\n",
       " '2011_005155',\n",
       " '2011_004628',\n",
       " '2008_001853',\n",
       " '2009_002899',\n",
       " '2008_007727',\n",
       " '2011_005384',\n",
       " '2011_000480',\n",
       " '2010_002249',\n",
       " '2009_000639',\n",
       " '2011_006664',\n",
       " '2012_001942',\n",
       " '2012_000943',\n",
       " '2011_006614',\n",
       " '2008_003199',\n",
       " '2009_004057',\n",
       " '2012_004045',\n",
       " '2011_004229',\n",
       " '2011_005871',\n",
       " '2008_002915',\n",
       " '2010_002600',\n",
       " '2011_005143',\n",
       " '2008_000353',\n",
       " '2011_000387',\n",
       " '2008_007144',\n",
       " '2009_001302',\n",
       " '2008_003887',\n",
       " '2009_001681',\n",
       " '2008_001861',\n",
       " '2008_004503',\n",
       " '2011_000781',\n",
       " '2009_004380',\n",
       " '2008_003599',\n",
       " '2010_004449',\n",
       " '2009_004054',\n",
       " '2008_006444',\n",
       " '2010_001953',\n",
       " '2010_006629',\n",
       " '2008_000954',\n",
       " '2008_003861',\n",
       " '2010_005357',\n",
       " '2011_006176',\n",
       " '2011_003071',\n",
       " '2012_002121',\n",
       " '2008_003919',\n",
       " '2008_004332',\n",
       " '2012_003249',\n",
       " '2010_004090',\n",
       " '2009_003940',\n",
       " '2011_002066',\n",
       " '2012_003079',\n",
       " '2009_004017',\n",
       " '2009_003684',\n",
       " '2010_001409',\n",
       " '2012_000645',\n",
       " '2008_008355',\n",
       " '2010_000917',\n",
       " '2009_005007',\n",
       " '2008_006172',\n",
       " '2012_000620',\n",
       " '2010_004993',\n",
       " '2011_006247',\n",
       " '2010_001809',\n",
       " '2011_001148',\n",
       " '2010_006260',\n",
       " '2009_001834',\n",
       " '2011_005403',\n",
       " '2010_005065',\n",
       " '2008_003828',\n",
       " '2008_007024',\n",
       " '2011_002207',\n",
       " '2012_003526',\n",
       " '2008_007074',\n",
       " '2010_004426',\n",
       " '2011_001696',\n",
       " '2011_004497',\n",
       " '2008_000072',\n",
       " '2008_005200',\n",
       " '2011_006109',\n",
       " '2008_006223',\n",
       " '2008_000175',\n",
       " '2008_000969',\n",
       " '2008_006891',\n",
       " '2009_001062',\n",
       " '2008_003142',\n",
       " '2011_007000',\n",
       " '2009_004015',\n",
       " '2010_000176',\n",
       " '2009_002757',\n",
       " '2010_004308',\n",
       " '2010_001964',\n",
       " '2009_001347',\n",
       " '2011_005576',\n",
       " '2008_002602',\n",
       " '2011_007140',\n",
       " '2010_004818',\n",
       " '2010_005322',\n",
       " '2010_003099',\n",
       " '2010_004240',\n",
       " '2010_005207',\n",
       " '2008_000241',\n",
       " '2009_000543',\n",
       " '2008_000840',\n",
       " '2010_005329',\n",
       " '2008_000482',\n",
       " '2010_000092',\n",
       " '2008_001762',\n",
       " '2008_002161',\n",
       " '2009_000556',\n",
       " '2010_005554',\n",
       " '2008_000961',\n",
       " '2012_002234',\n",
       " '2010_005490',\n",
       " '2011_001636',\n",
       " '2009_000850',\n",
       " '2009_001951',\n",
       " '2008_008596',\n",
       " '2008_000752',\n",
       " '2008_000767',\n",
       " '2009_004637',\n",
       " '2009_003871',\n",
       " '2010_006359',\n",
       " '2008_008491',\n",
       " '2008_005613',\n",
       " '2010_005240',\n",
       " '2008_002168',\n",
       " '2012_002215',\n",
       " '2008_008171',\n",
       " '2012_000630',\n",
       " '2008_008283',\n",
       " '2011_006023',\n",
       " '2009_000301',\n",
       " '2011_000825',\n",
       " '2010_000108',\n",
       " '2008_005532',\n",
       " '2008_005397',\n",
       " '2010_001026',\n",
       " '2011_004395',\n",
       " '2011_004216',\n",
       " '2008_004170',\n",
       " '2010_005617',\n",
       " '2010_000150',\n",
       " '2008_008592',\n",
       " '2008_001019',\n",
       " '2008_006196',\n",
       " '2008_005815',\n",
       " '2010_003289',\n",
       " '2008_003190',\n",
       " '2008_007406',\n",
       " '2011_002416',\n",
       " '2012_001223',\n",
       " '2012_000423',\n",
       " '2012_003704',\n",
       " '2012_003029',\n",
       " '2011_002607',\n",
       " '2010_004985',\n",
       " '2010_005694',\n",
       " '2011_002734',\n",
       " '2012_001373',\n",
       " '2010_000410',\n",
       " '2011_006210',\n",
       " '2010_005931',\n",
       " '2010_003872',\n",
       " '2011_005024',\n",
       " '2010_002506',\n",
       " '2011_001996',\n",
       " '2011_006444',\n",
       " '2008_000478',\n",
       " '2010_004886',\n",
       " '2008_001146',\n",
       " '2009_002598',\n",
       " '2010_003584',\n",
       " '2008_005551',\n",
       " '2008_006675',\n",
       " '2011_004767',\n",
       " '2008_008540',\n",
       " '2010_006288',\n",
       " '2008_000872',\n",
       " '2009_003585',\n",
       " '2008_000642',\n",
       " '2008_007126',\n",
       " '2009_003678',\n",
       " '2008_004618',\n",
       " '2009_000256',\n",
       " '2010_002125',\n",
       " '2008_002661',\n",
       " '2008_004596',\n",
       " '2012_000569',\n",
       " '2008_001363',\n",
       " '2010_000205',\n",
       " '2010_005404',\n",
       " '2008_004511',\n",
       " '2010_003087',\n",
       " '2010_003262',\n",
       " '2011_004865',\n",
       " '2011_004567',\n",
       " '2010_001567',\n",
       " '2010_004949',\n",
       " '2012_002312',\n",
       " '2008_005466',\n",
       " '2008_003401',\n",
       " '2009_003692',\n",
       " '2009_004690',\n",
       " '2011_000026',\n",
       " '2011_002856',\n",
       " '2011_001469',\n",
       " '2008_006830',\n",
       " '2010_004277',\n",
       " '2008_002744',\n",
       " '2011_004222',\n",
       " '2011_003632',\n",
       " '2008_000913',\n",
       " '2010_001460',\n",
       " '2008_001200',\n",
       " '2012_000511',\n",
       " '2008_005320',\n",
       " '2011_003092',\n",
       " ...]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imagenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/test/VOCdevkit/VOC2012//JPEGImages/2008_008699.jpg',\n",
       " './data/test/VOCdevkit/VOC2012//JPEGImages/2010_004633.jpg',\n",
       " './data/test/VOCdevkit/VOC2012//JPEGImages/2008_004211.jpg',\n",
       " './data/test/VOCdevkit/VOC2012//JPEGImages/2008_003555.jpg',\n",
       " './data/test/VOCdevkit/VOC2012//JPEGImages/2008_004294.jpg']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set(imagenames) & set(voc_2007[0].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class VOCDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, folderpath, sample=-1, transform=None, files = [], max_truth=30):\n",
    "        \n",
    "        \"\"\"\n",
    "            Reading all image names without the extension.\n",
    "        \"\"\"\n",
    "        names = glob.glob(folderpath+ \"/JPEGImages/*.jpg\")\n",
    "        self.imagenames = [re.split(\"\\\\.\", re.split(\"\\\\/\", names[i])[-1])[0] for i in range(len(names))]\n",
    "        self.imagenames = list(set(self.imagenames) & set(files))\n",
    "        np.random.shuffle(self.imagenames)\n",
    "        if sample != -1:\n",
    "            self.imagenames = self.imagenames[:sample]\n",
    "        self.folderpath = folderpath\n",
    "        self.transform = transform\n",
    "        self.max_truth = max_truth\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.imagenames)\n",
    "    \n",
    "    \n",
    "    def parse_xml(self, xml_file):\n",
    "        # actual parsing \n",
    "        in_file = open(xml_file)\n",
    "        tree = ET.parse(in_file)\n",
    "        root = tree.getroot()\n",
    "        imsize = root.find('size')\n",
    "        w = int(imsize.find('width').text)\n",
    "        h = int(imsize.find('height').text)\n",
    "        all_bboxes = list()\n",
    "\n",
    "        for obj in root.iter('object'):\n",
    "            current = list()\n",
    "            name = obj.find('name').text\n",
    "            \n",
    "            class_id = np.argwhere(classes==name)[0][0]\n",
    "            \n",
    "            xmlbox = obj.find('bndbox')\n",
    "            xn = int(float(xmlbox.find('xmin').text))\n",
    "            xx = int(float(xmlbox.find('xmax').text))\n",
    "            yn = int(float(xmlbox.find('ymin').text))\n",
    "            yx = int(float(xmlbox.find('ymax').text))\n",
    "            current = np.array([class_id,xn,yn,xx,yx])\n",
    "            all_bboxes += [current]\n",
    "        \n",
    "        in_file.close()\n",
    "        return np.array(all_bboxes)\n",
    "\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        imagename = self.imagenames[idx]\n",
    "        image_file = os.path.join(self.folderpath, \"JPEGImages\", imagename + \".jpg\")\n",
    "        annotation_file = os.path.join(self.folderpath, \"Annotations\", imagename + \".xml\")\n",
    "        \n",
    "        bboxes = self.parse_xml(annotation_file)\n",
    "        \n",
    "        img_array = np.asarray(Image.open(open(image_file)))\n",
    "        datum = {\"image\": img_array, \"bboxes\": bboxes}\n",
    "            \n",
    "        if self.transform:\n",
    "            datum = self.transform(datum)\n",
    "\n",
    "        bboxes = datum['bboxes'].numpy()\n",
    "        \n",
    "        n_true = len(bboxes)\n",
    "        if len(bboxes) > self.max_truth:\n",
    "            bboxes = bboxes[:self.max_truth]\n",
    "            n_true = self.max_truth\n",
    "        else:\n",
    "            zero_fill = self.max_truth - len(bboxes)\n",
    "            null_pad = -1 * (np.ones(5*zero_fill).reshape(zero_fill, 5))\n",
    "            if n_true == 0:\n",
    "                bboxes = null_pad\n",
    "            else:\n",
    "                bboxes = np.concatenate([bboxes, null_pad])\n",
    "        \n",
    "        datum['bboxes'] = torch.from_numpy(bboxes)\n",
    "        datum['n_true'] = n_true\n",
    "        return datum\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2012 = pd.read_csv(\"./data/train/VOCdevkit/VOC2012/ImageSets/Main/train.txt\", \n",
    "                        sep='\\s+', header=-1)\n",
    "val2012 = pd.read_csv(\"./data/train/VOCdevkit/VOC2012/ImageSets/Main/val.txt\", \n",
    "                      sep='\\s+', header=-1)\n",
    "voc_train2012 = pd.concat([train2012, val2012]).drop_duplicates()\n",
    "\n",
    "voc_train2012.columns = ['filepath']\n",
    "voc_train2012[\"train\"] = 1\n",
    "\n",
    "voc_2012 = pd.DataFrame({\"filepath\":\n",
    "                         glob.glob(\"./data/train/VOCdevkit/VOC2012/JPEGImages/*.jpg\")})\n",
    "voc_2012[\"filepath\"] = voc_2012['filepath'].map(lambda x: re.split(\"\\\\.\", re.split(\"\\\\/\", x)[-1])[0])\n",
    "voc_2012 = pd.merge(voc_2012, voc_train2012, on=\"filepath\", how=\"left\")\n",
    "voc_2012.fillna(0, inplace=True)\n",
    "\n",
    "#### \n",
    "# 2007 dataset\n",
    "########\n",
    "train_2007 = pd.read_csv(\"./data/train/VOCdevkit/VOC2007/ImageSets/Main/train.txt\", sep='\\s+', header=-1, dtype='str')\n",
    "val_2007 = pd.read_csv(\"./data/train/VOCdevkit/VOC2007/ImageSets/Main/val.txt\", sep='\\s+', header=-1, dtype='str')\n",
    "test_2007 = pd.read_csv(\"./data/test/VOCdevkit/VOC2007/ImageSets/Main/test.txt\", sep='\\s+', header=-1, dtype='str')\n",
    "\n",
    "voc_2007 = pd.concat([train_2007, val_2007, test_2007]).drop_duplicates()\n",
    "voc_2007.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(image_size=416, sample=-1, batch_size=64):\n",
    "    transform_fn = transforms.Compose([RandomCrop(), \n",
    "                                   RandomFlip(), \n",
    "                                   Rescale((image_size, image_size)), \n",
    "                                   TransformBoxCoords(), \n",
    "                                   Normalize(),\n",
    "                                   EliminateSmallBoxes(0.025),\n",
    "                                   ToTensor()])\n",
    "    \n",
    "    voc_train_12 = VOCDataset(\"./data/train/VOCdevkit/VOC2012/\", sample=sample, transform=transform_fn,\n",
    "                        files=voc_2012[voc_2012[\"train\"]==1][\"filepath\"].values)\n",
    "    voc_test_12 = VOCDataset(\"./data/test/VOCdevkit/VOC2012/\", sample=sample, transform=transform_fn,\n",
    "                            files=voc_2012[voc_2012[\"train\"]==0][\"filepath\"].values)\n",
    "    voc_train_07 = VOCDataset(\"./data/train/VOCdevkit/VOC2007/\", sample=sample, transform=transform_fn,\n",
    "                            files=voc_2007[0].values)\n",
    "#     voc_test_07 = VOCDataset(\"./data/test/VOCdevkit/VOC2007/\", sample=sample, transform=transform_fn,\n",
    "#                             files=voc_2007[voc_2007[\"train\"]==0][\"filepath\"].values)\n",
    "\n",
    "    # Dataloader\n",
    "    \n",
    "    train_loader = DataLoader(ConcatDataset([voc_train_07, voc_train_12]), \n",
    "                              batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "    test_loader = DataLoader(voc_test_12, batch_size=batch_size, num_workers=4)\n",
    "    return train_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class define for conv, maxpool and others\n",
    "class Yolov2(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(Yolov2, self).__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm1 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm2 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm3 = nn.BatchNorm2d(128)\n",
    "        self.conv4 = nn.Conv2d(in_channels=128, out_channels=64, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batchnorm4 = nn.BatchNorm2d(64)\n",
    "        self.conv5 = nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm5 = nn.BatchNorm2d(128)\n",
    "        \n",
    "        self.conv6 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm6 = nn.BatchNorm2d(256)\n",
    "        self.conv7 = nn.Conv2d(in_channels=256, out_channels=128, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batchnorm7 = nn.BatchNorm2d(128)\n",
    "        self.conv8 = nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm8 = nn.BatchNorm2d(256)\n",
    "        \n",
    "        self.conv9 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm9 = nn.BatchNorm2d(512)\n",
    "        self.conv10 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batchnorm10 = nn.BatchNorm2d(256)\n",
    "        self.conv11 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm11 = nn.BatchNorm2d(512)\n",
    "        self.conv12 = nn.Conv2d(in_channels=512, out_channels=256, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batchnorm12 = nn.BatchNorm2d(256)\n",
    "        self.conv13 = nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm13 = nn.BatchNorm2d(512)\n",
    "        \n",
    "        self.conv14 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm14 = nn.BatchNorm2d(1024)\n",
    "        self.conv15 = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batchnorm15 = nn.BatchNorm2d(512)\n",
    "        self.conv16 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm16 = nn.BatchNorm2d(1024)\n",
    "        self.conv17 = nn.Conv2d(in_channels=1024, out_channels=512, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.batchnorm17 = nn.BatchNorm2d(512)\n",
    "        self.conv18 = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm18 = nn.BatchNorm2d(1024)\n",
    "\n",
    "        self.conv19 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm19 = nn.BatchNorm2d(1024)\n",
    "        self.conv20 = nn.Conv2d(in_channels=1024, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm20 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv21 = nn.Conv2d(in_channels=3072, out_channels=1024, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.batchnorm21 = nn.BatchNorm2d(1024)\n",
    "        \n",
    "        self.conv22 = nn.Conv2d(in_channels=1024, out_channels=125, kernel_size=1, stride=1, padding=0)\n",
    "        \n",
    "    def reorg_layer(self, x):\n",
    "        stride = 2\n",
    "        batch_size, channels, height, width = x.size()\n",
    "        new_ht = height/stride\n",
    "        new_wd = width/stride\n",
    "        new_channels = channels * stride * stride\n",
    "        \n",
    "        passthrough = x.permute(0, 2, 3, 1)\n",
    "        passthrough = passthrough.contiguous().view(-1, new_ht, stride, new_wd, stride, channels)\n",
    "        passthrough = passthrough.permute(0, 1, 3, 2, 4, 5)\n",
    "        passthrough = passthrough.contiguous().view(-1, new_ht, new_wd, new_channels)\n",
    "        passthrough = passthrough.permute(0, 3, 1, 2)\n",
    "        return passthrough\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.max_pool2d(F.leaky_relu(self.batchnorm1(self.conv1(x)), negative_slope=0.1), 2, stride=2)\n",
    "        out = F.max_pool2d(F.leaky_relu(self.batchnorm2(self.conv2(out)), negative_slope=0.1), 2, stride=2)\n",
    "        \n",
    "        out = F.leaky_relu(self.batchnorm3(self.conv3(out)), negative_slope=0.1)\n",
    "        out = F.leaky_relu(self.batchnorm4(self.conv4(out)), negative_slope=0.1)\n",
    "        out = F.leaky_relu(self.batchnorm5(self.conv5(out)), negative_slope=0.1)\n",
    "        out = F.max_pool2d(out, 2, stride=2)\n",
    "        \n",
    "        out = F.leaky_relu(self.batchnorm6(self.conv6(out)), negative_slope=0.1)\n",
    "        out = F.leaky_relu(self.batchnorm7(self.conv7(out)), negative_slope=0.1)\n",
    "        out = F.leaky_relu(self.batchnorm8(self.conv8(out)), negative_slope=0.1)\n",
    "        out = F.max_pool2d(out, 2, stride=2)\n",
    "\n",
    "        out = F.leaky_relu(self.batchnorm9(self.conv9(out)), negative_slope=0.1)\n",
    "        out = F.leaky_relu(self.batchnorm10(self.conv10(out)), negative_slope=0.1)\n",
    "        out = F.leaky_relu(self.batchnorm11(self.conv11(out)), negative_slope=0.1)\n",
    "        out = F.leaky_relu(self.batchnorm12(self.conv12(out)), negative_slope=0.1)\n",
    "        out = F.leaky_relu(self.batchnorm13(self.conv13(out)), negative_slope=0.1)\n",
    "        passthrough = self.reorg_layer(out)\n",
    "        out = F.max_pool2d(out, 2, stride=2)\n",
    "\n",
    "        out = F.leaky_relu(self.batchnorm14(self.conv14(out)), negative_slope=0.1)\n",
    "        out = F.leaky_relu(self.batchnorm15(self.conv15(out)), negative_slope=0.1)\n",
    "        out = F.leaky_relu(self.batchnorm16(self.conv16(out)), negative_slope=0.1)\n",
    "        out = F.leaky_relu(self.batchnorm17(self.conv17(out)), negative_slope=0.1)\n",
    "        out = F.leaky_relu(self.batchnorm18(self.conv18(out)), negative_slope=0.1)\n",
    "\n",
    "        out = F.leaky_relu(self.batchnorm19(self.conv19(out)), negative_slope=0.1)\n",
    "        out = F.leaky_relu(self.batchnorm20(self.conv20(out)), negative_slope=0.1)\n",
    "        \n",
    "        out = torch.cat([passthrough, out], 1)\n",
    "        out = F.leaky_relu(self.batchnorm21(self.conv21(out)), negative_slope=0.1)\n",
    "        out = self.conv22(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def load_pretrained_weights(model):\n",
    "#     group_mapping = defaultdict(lambda: defaultdict())\n",
    "#     cnt = 0\n",
    "#     for child in model.children():\n",
    "#         if type(child) == nn.Conv2d:\n",
    "#             cnt += 1\n",
    "#             if cnt > 18:\n",
    "#                 break\n",
    "#             group_mapping[cnt]['conv'] = child\n",
    "#             group_mapping[cnt]['bias'] = child\n",
    "#         else:\n",
    "#             group_mapping[cnt]['bias'] = child\n",
    "\n",
    "\n",
    "#     f = open('../darknet19_448.conv.23', 'rb')\n",
    "# #     f = open('../yolo.weights', 'rb')\n",
    "#     major, minor, revision, seen = struct.unpack('4i', f.read(16))\n",
    "#     for i in range(1, 19):\n",
    "\n",
    "#         bias_var = group_mapping[i]['bias']\n",
    "#         cnt = int(bias_var.bias.size()[0])\n",
    "#         bias_var.bias.data = torch.from_numpy(np.array(struct.unpack('%df' % cnt, f.read(4*cnt)))).float()\n",
    "#         bias_var.weight.data = torch.from_numpy(np.array(struct.unpack('%df' % cnt, f.read(4*cnt)))).float()\n",
    "#         bias_var.running_mean = torch.from_numpy(np.array(struct.unpack('%df' % cnt, f.read(4*cnt)))).float()\n",
    "#         bias_var.running_var = torch.from_numpy(np.array(struct.unpack('%df' % cnt, f.read(4*cnt)))).float()\n",
    "\n",
    "#         for param in bias_var.parameters():\n",
    "#             param.requires_grad = False\n",
    "\n",
    "#         conv_var = group_mapping[i]['conv']\n",
    "#         c_out, c_in, f1, f2 = conv_var.weight.size()\n",
    "#         cnt = int(c_out * c_in * f1 * f2)\n",
    "#         p = struct.unpack('%df' % cnt, f.read(4*cnt))\n",
    "#         conv_var.weight.data = torch.from_numpy(np.reshape(p, [c_out, c_in, f1, f2])).float()\n",
    "#         for param in conv_var.parameters():\n",
    "#             param.requires_grad = False\n",
    "    \n",
    "#     return model\n",
    "\n",
    "\n",
    "def get_model():\n",
    "    model = Yolov2()\n",
    "#     model = load_pretrained_weights(model)\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "    return model\n",
    "\n",
    "    \n",
    "# def model_freeze_upto(model, layer_x):\n",
    "#     childs = list(model.children())\n",
    "#     for i in range(len(childs)):\n",
    "#         child = childs[i]\n",
    "#         for param in child.parameters():\n",
    "#             if i < layer_x:\n",
    "#                 param.requires_grad = False\n",
    "#             else:\n",
    "#                 param.requires_grad = True\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox_overlap_iou(bboxes1, bboxes2, is_anchor):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        bboxes1: shape (total_bboxes1, 4)\n",
    "            with x1, y1, x2, y2 point order.\n",
    "        bboxes2: shape (total_bboxes2, 4)\n",
    "            with x1, y1, x2, y2 point order.\n",
    "        p1 *-----        \n",
    "           |     |\n",
    "           |_____* p2\n",
    "    Returns:\n",
    "        Tensor with shape (total_bboxes1, total_bboxes2)\n",
    "        with the IoU (intersection over union) of bboxes1[i] and bboxes2[j]\n",
    "        in [i, j].\n",
    "    \"\"\"\n",
    "#     import pdb; pdb.set_trace()\n",
    "    x1, y1, w1, h1 = bboxes1.chunk(4, dim=-1)\n",
    "    x2, y2, w2, h2 = bboxes2.chunk(4, dim=-1)\n",
    "    \n",
    "    x11 = x1 - 0.5*w1\n",
    "    y11 = y1 - 0.5*h1\n",
    "    x12 = x1 + 0.5*w1\n",
    "    y12 = y1 + 0.5*h1\n",
    "    x21 = x2 - 0.5*w2\n",
    "    y21 = y2 - 0.5*h2\n",
    "    x22 = x2 + 0.5*w2\n",
    "    y22 = y2 + 0.5*h2\n",
    "    \n",
    "#     x11 = torch.clamp(x11, min=0, max=1)\n",
    "#     y11 = torch.clamp(y11, min=0, max=1)\n",
    "#     x12 = torch.clamp(x12, min=0, max=1)\n",
    "#     y12 = torch.clamp(y12, min=0, max=1)\n",
    "#     x21 = torch.clamp(x21, min=0, max=1)\n",
    "#     y21 = torch.clamp(y21, min=0, max=1)\n",
    "#     x22 = torch.clamp(x22, min=0, max=1)\n",
    "#     y22 = torch.clamp(y22, min=0, max=1)\n",
    "    \n",
    "\n",
    "    xI1 = torch.max(x11, x21.transpose(1, 0))\n",
    "    yI1 = torch.max(y11, y21.transpose(1, 0))\n",
    "    \n",
    "    xI2 = torch.min(x12, x22.transpose(1, 0))\n",
    "    yI2 = torch.min(y12, y22.transpose(1, 0))\n",
    "\n",
    "    inner_box_w = torch.clamp((xI2 - xI1), min=0)\n",
    "    inner_box_h = torch.clamp((yI2 - yI1), min=0)\n",
    "    \n",
    "    inter_area = inner_box_w * inner_box_h\n",
    "    bboxes1_area = (x12 - x11) * (y12 - y11)\n",
    "    bboxes2_area = (x22 - x21) * (y22 - y21)\n",
    "\n",
    "    union = (bboxes1_area + bboxes2_area.transpose(1, 0)) - inter_area\n",
    "    return torch.clamp(inter_area / union, min=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def Yolov2Loss(output, labels, n_truths):\n",
    "    B = meta['anchors']\n",
    "    C = meta['classes']\n",
    "    batch_size = meta['batch_size']\n",
    "    threshold = meta['threshold']\n",
    "    anchor_bias = meta['anchor_bias']\n",
    "    scale_no_obj = meta['scale_no_obj']\n",
    "    scale_coords = meta['scale_coords']\n",
    "    scale_class = meta['scale_class']\n",
    "    scale_obj = meta['scale_obj']\n",
    "    \n",
    "    H = output.size(2)\n",
    "    W = output.size(3)\n",
    "    \n",
    "    wh = Variable(torch.from_numpy(np.reshape([W, H], [1, 1, 1, 1, 2]))).float()\n",
    "    anchor_bias_var = Variable(torch.from_numpy(np.reshape(anchor_bias, [1, 1, 1, B, 2]))).float()\n",
    "    \n",
    "    w_list = np.array(list(range(W)), np.float32)\n",
    "    wh_ids = Variable(torch.from_numpy(np.array(list(map(lambda x: np.array(list(itertools.product(w_list, [x]))), range(H)))).reshape(1, H, W, 1, 2))).float() \n",
    "    \n",
    "    zero_pad = Variable(torch.zeros(2).contiguous().view(1, 2)).float()\n",
    "    pad_var = Variable(torch.zeros(2*B).contiguous().view(B, 2)).float()\n",
    "    \n",
    "    loss = Variable(torch.Tensor([0])).float()\n",
    "    class_zeros = Variable(torch.zeros(C)).float()\n",
    "    mask_loss = Variable(torch.zeros(H*W*B*5).contiguous().view(H, W, B, 5)).float()\n",
    "    zero_coords_loss = Variable(torch.zeros(H*W*B*4).contiguous().view(H, W, B, 4)).float()\n",
    "    zero_coords_obj_loss = Variable(torch.zeros(H*W*B*5).contiguous().view(H, W, B, 5)).float()\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        wh = wh.cuda()\n",
    "        wh_ids = wh_ids.cuda()\n",
    "        pad_var = pad_var.cuda()\n",
    "        zero_pad = zero_pad.cuda()\n",
    "        anchor_bias_var = anchor_bias_var.cuda()\n",
    "        \n",
    "        loss = loss.cuda()\n",
    "        mask_loss = mask_loss.cuda()\n",
    "        class_zeros = class_zeros.cuda()\n",
    "        zero_coords_loss = zero_coords_loss.cuda()\n",
    "        zero_coords_obj_loss = zero_coords_obj_loss.cuda()\n",
    "                           \n",
    "\n",
    "    anchor_bias_var = anchor_bias_var / wh\n",
    "    anchor_padded = torch.cat([pad_var, anchor_bias_var.contiguous().view(B, 2)], 1)\n",
    "\n",
    "    predicted = output.permute(0, 2, 3, 1)\n",
    "    predicted = predicted.contiguous().view(-1, H, W, B, (4 + 1 + C))\n",
    "    \n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    softmax = torch.nn.Softmax(dim=4)\n",
    "    \n",
    "    adjusted_xy = sigmoid(predicted[:, :, :, :, :2])\n",
    "    adjusted_obj = sigmoid(predicted[:, :, :, :, 4:5])\n",
    "    adjusted_classes = softmax(predicted[:, :, :, :, 5:])\n",
    "    \n",
    "    adjusted_coords = (adjusted_xy + wh_ids) / wh\n",
    "\n",
    "    adjusted_wh = torch.exp(predicted[:, :, :, :, 2:4]) * anchor_bias_var\n",
    "    \n",
    "    for batch in range(batch_size):\n",
    "        \n",
    "        n_true = n_truths[batch]\n",
    "        if n_true == 0:\n",
    "            continue\n",
    "\n",
    "        pred_outputs = torch.cat([adjusted_coords[batch], adjusted_wh[batch]], 3)\n",
    "        true_labels = labels[batch, :n_true, 1:]\n",
    "        \n",
    "        bboxes_iou = bbox_overlap_iou(pred_outputs, true_labels, False)\n",
    "        \n",
    "        # objectness loss (if iou < threshold)\n",
    "        boxes_max_iou = torch.max(bboxes_iou, -1)[0]\n",
    "        all_obj_mask = boxes_max_iou.le(threshold)\n",
    "        all_obj_loss = all_obj_mask.unsqueeze(-1).float() *(scale_no_obj * (-1 * adjusted_obj[batch]))\n",
    "        \n",
    "        # each anchor box will learn its bias (if batch < 12800)\n",
    "        all_coords_loss = zero_coords_loss.clone()\n",
    "        if meta['iteration'] < 12800:\n",
    "            all_coords_loss = scale_coords * torch.cat([(0.5 - adjusted_xy[batch]), (0 - predicted[batch, :, :, :, 2:4])], -1)\n",
    "        \n",
    "        coord_obj_loss = torch.cat([all_coords_loss, all_obj_loss], -1)\n",
    "        \n",
    "        batch_mask = mask_loss.clone()\n",
    "        truth_coord_obj_loss = zero_coords_obj_loss.clone()\n",
    "        # for every true label and anchor bias\n",
    "        for truth_iter in torch.arange(n_true):\n",
    "            truth_iter = int(truth_iter)\n",
    "            truth_box = labels[batch, truth_iter]\n",
    "            anchor_select = bbox_overlap_iou(torch.cat([zero_pad.t(), truth_box[3:]], 0).t(), anchor_padded, True)\n",
    "            \n",
    "            # find the responsible anchor box\n",
    "            anchor_id = torch.max(anchor_select, 1)[1]\n",
    "            \n",
    "            truth_i = (truth_box[1] * W)\n",
    "            w_i = truth_i.int() \n",
    "            truth_x = truth_i - w_i.float()\n",
    "            truth_j = (truth_box[2] * H)\n",
    "            h_j = truth_j.int()\n",
    "            truth_y = truth_j - h_j.float()\n",
    "            truth_wh = (truth_box[3:] / anchor_bias_var.contiguous().view(B, 2).index_select(0, anchor_id.long())).log()\n",
    "            if (truth_wh[0] == Variable( - torch.cuda.FloatTensor([float('inf')]))).data[0] == 1:\n",
    "                import pdb; pdb.set_trace()\n",
    "    \n",
    "            truth_coords = torch.cat([truth_x.unsqueeze(0), truth_y.unsqueeze(0), truth_wh], 1)\n",
    "            \n",
    "            predicted_output = predicted[batch].index_select(0, h_j.long()).index_select(1, w_i.long()).index_select(2, anchor_id.long())[0][0][0]\n",
    "            # coords loss\n",
    "            pred_xy = adjusted_xy[batch].index_select(0, h_j.long()).index_select(1, w_i.long()).index_select(2, anchor_id.long())[0][0][0]\n",
    "            pred_wh = predicted_output[2:4]\n",
    "            pred_coords = torch.cat([pred_xy, pred_wh], 0)\n",
    "            coords_loss = scale_coords * (truth_coords - pred_coords.unsqueeze(0))\n",
    "    \n",
    "            # objectness loss\n",
    "        \n",
    "            # given the responsible box - find iou\n",
    "            iou = bboxes_iou.index_select(0, h_j.long()).index_select(1, w_i.long()).index_select(2, anchor_id.long())[0][0][0][truth_iter]\n",
    "            obj_loss = scale_obj * (iou - sigmoid(predicted_output[4]))\n",
    "            truth_co_obj = torch.cat([coords_loss, obj_loss.view(1, 1)], 1)\n",
    "\n",
    "            # class prob loss\n",
    "            class_vec = class_zeros.index_fill(0, truth_box[0].long(), 1)\n",
    "            class_loss = scale_class * (class_vec - torch.nn.Softmax(dim=0)(predicted_output[5:]))\n",
    "            \n",
    "            mask_ones = Variable(torch.ones(5)).float()\n",
    "            if torch.cuda.is_available():\n",
    "                mask_ones = mask_ones.cuda()\n",
    "            \n",
    "            batch_mask[h_j.long(), w_i.long(), anchor_id.long()] = mask_ones\n",
    "            truth_coord_obj_loss[h_j.long(), w_i.long(), anchor_id.long()] = truth_co_obj\n",
    "            \n",
    "            loss += class_loss.pow(2).sum()\n",
    "#         import pdb; pdb.set_trace()\n",
    "        batch_coord_obj_loss = batch_mask * truth_coord_obj_loss + (1 - batch_mask) * coord_obj_loss\n",
    "        \n",
    "        loss += batch_coord_obj_loss.pow(2).sum()\n",
    "        \n",
    "    return loss\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nms_boxes(output, obj_thresh, iou_thresh):\n",
    "#     import pdb; pdb.set_trace()\n",
    "    N, C, H, W = output.size()\n",
    "    N, C, H, W = int(N), int(C), int(H), int(W)\n",
    "    B = meta['anchors']\n",
    "    anchor_bias = meta['anchor_bias']\n",
    "    n_classes = meta['classes']\n",
    "    \n",
    "    # -1 => unprocesse, 0 => suppressed, 1 => retained\n",
    "    box_tags = Variable(-1 * torch.ones(H*W*B)).float()\n",
    "    \n",
    "    wh = Variable(torch.from_numpy(np.reshape([W, H], [1, 1, 1, 1, 2]))).float()\n",
    "    anchor_bias_var = Variable(torch.from_numpy(np.reshape(anchor_bias, [1, 1, 1, B, 2]))).float()\n",
    "    \n",
    "    w_list = np.array(list(range(W)), np.float32)\n",
    "    wh_ids = Variable(torch.from_numpy(np.array(list(map(lambda x: np.array(list(itertools.product(w_list, [x]))), range(H)))).reshape(1, H, W, 1, 2))).float() \n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        wh = wh.cuda()\n",
    "        wh_ids = wh_ids.cuda()\n",
    "        box_tags = box_tags.cuda()\n",
    "        anchor_bias_var = anchor_bias_var.cuda()                           \n",
    "\n",
    "    anchor_bias_var = anchor_bias_var / wh\n",
    "\n",
    "    predicted = output.permute(0, 2, 3, 1)\n",
    "    predicted = predicted.contiguous().view(N, H, W, B, -1)\n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    softmax = torch.nn.Softmax(dim=4)\n",
    "    \n",
    "    adjusted_xy = sigmoid(predicted[:, :, :, :, :2])\n",
    "    adjusted_obj = sigmoid(predicted[:, :, :, :, 4:5])\n",
    "    adjusted_classes = softmax(predicted[:, :, :, :, 5:])\n",
    "    \n",
    "    adjusted_coords = (adjusted_xy + wh_ids) / wh\n",
    "    adjusted_wh = torch.exp(predicted[:, :, :, :, 2:4]) * anchor_bias_var\n",
    "\n",
    "    batch_boxes = defaultdict()\n",
    "\n",
    "    for n in range(N):\n",
    "        \n",
    "        scores = (adjusted_obj[n] * adjusted_classes[n]).contiguous().view(H*W*B, -1)\n",
    "    \n",
    "        class_probs = adjusted_classes[n].contiguous().view(H*W*B, -1)\n",
    "        class_ids = torch.max(class_probs, 1)[1]\n",
    "            \n",
    "        pred_outputs = torch.cat([adjusted_coords[n], adjusted_wh[n]], 3)\n",
    "        pred_bboxes = pred_outputs.contiguous().view(H*W*B, 4)\n",
    "        ious = bbox_overlap_iou(pred_bboxes, pred_bboxes, True)\n",
    "        \n",
    "        confidences = adjusted_obj[n].contiguous().view(H*W*B)\n",
    "        # get all boxes with tag -1\n",
    "        final_boxes = Variable(torch.FloatTensor())\n",
    "        if torch.cuda.is_available():\n",
    "            final_boxes = final_boxes.cuda()\n",
    "   \n",
    "        for class_id in range(n_classes):\n",
    "            bboxes_state = ((class_ids==class_id).float() * (scores[:, class_id] > obj_thresh).float() * box_tags).long().float()\n",
    "        \n",
    "            while (torch.sum(bboxes_state==-1) > 0).data[0]:\n",
    "                max_conf, index = torch.max(scores[:, class_id] * (bboxes_state==-1).float(), 0)\n",
    "                bboxes_state = ((ious[index] < iou_thresh)[0].float() * bboxes_state).long().float()\n",
    "                bboxes_state[index] = 1\n",
    "\n",
    "                index_vals = torch.cat([pred_bboxes[index], confidences[index].view(1, 1), class_probs[index]], 1)\n",
    "                if len(final_boxes.size()) == 0:\n",
    "                    final_boxes = index_vals\n",
    "                else:\n",
    "                    final_boxes = torch.cat([final_boxes, index_vals], 0)\n",
    "        \n",
    "        batch_boxes[n] = final_boxes\n",
    "        \n",
    "    return batch_boxes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non Max Suppression\n",
    "def get_nms_detections(output, obj_thresh, iou_thresh):\n",
    "#     import pdb; pdb.set_trace()\n",
    "    N, C, H, W = output.size()\n",
    "    N, C, H, W = int(N), int(C), int(H), int(W)\n",
    "    B = meta['anchors']\n",
    "    anchor_bias = meta['anchor_bias']\n",
    "    \n",
    "    # -1 => unprocesse, 0 => suppressed, 1 => retained\n",
    "    box_tags = Variable(-1 * torch.ones(H*W*B)).float()\n",
    "    \n",
    "    wh = Variable(torch.from_numpy(np.reshape([W, H], [1, 1, 1, 1, 2]))).float()\n",
    "    anchor_bias_var = Variable(torch.from_numpy(np.reshape(anchor_bias, [1, 1, 1, B, 2]))).float()\n",
    "    \n",
    "    w_list = np.array(list(range(W)), np.float32)\n",
    "    wh_ids = Variable(torch.from_numpy(np.array(list(map(lambda x: np.array(list(itertools.product(w_list, [x]))), range(H)))).reshape(1, H, W, 1, 2))).float() \n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        wh = wh.cuda()\n",
    "        wh_ids = wh_ids.cuda()\n",
    "        box_tags = box_tags.cuda()\n",
    "        anchor_bias_var = anchor_bias_var.cuda()                           \n",
    "\n",
    "    anchor_bias_var = anchor_bias_var / wh\n",
    "\n",
    "    predicted = output.permute(0, 2, 3, 1)\n",
    "    predicted = predicted.contiguous().view(N, H, W, B, -1)\n",
    "    \n",
    "\n",
    "    \n",
    "    sigmoid = torch.nn.Sigmoid()\n",
    "    softmax = torch.nn.Softmax(dim=4)\n",
    "    \n",
    "    adjusted_xy = sigmoid(predicted[:, :, :, :, :2])\n",
    "    adjusted_obj = sigmoid(predicted[:, :, :, :, 4:5])\n",
    "    adjusted_classes = softmax(predicted[:, :, :, :, 5:])\n",
    "    \n",
    "    adjusted_coords = (adjusted_xy + wh_ids) / wh\n",
    "    adjusted_wh = torch.exp(predicted[:, :, :, :, 2:4]) * anchor_bias_var\n",
    "\n",
    "    batch_boxes = defaultdict()\n",
    "\n",
    "    for n in range(N):\n",
    "        \n",
    "        class_probs = adjusted_classes[n].contiguous().view(H*W*B, -1)\n",
    "        pred_outputs = torch.cat([adjusted_coords[n], adjusted_wh[n]], 3)\n",
    "        pred_bboxes = pred_outputs.contiguous().view(H*W*B, 4)\n",
    "        ious = bbox_overlap_iou(pred_bboxes, pred_bboxes, True)\n",
    "        \n",
    "        confidences = adjusted_obj[n].contiguous().view(H*W*B)\n",
    "        bboxes_state = ((confidences>obj_thresh).float() * box_tags).long().float()\n",
    "        \n",
    "        # get all boxes with tag -1\n",
    "        final_boxes = Variable(torch.FloatTensor())\n",
    "        if torch.cuda.is_available():\n",
    "            final_boxes = final_boxes.cuda()\n",
    "        while (torch.sum(bboxes_state==-1) > 0).data[0]:\n",
    "            max_conf, index = torch.max(confidences * (bboxes_state==-1).float(), 0)\n",
    "            bboxes_state = ((ious[index] < iou_thresh)[0].float() * bboxes_state).long().float()\n",
    "            bboxes_state[index] = 1\n",
    "            \n",
    "            index_vals = torch.cat([pred_bboxes[index], confidences[index].view(1, 1), class_probs[index]], 1)\n",
    "            if len(final_boxes.size()) == 0:\n",
    "                final_boxes = index_vals\n",
    "            else:\n",
    "                final_boxes = torch.cat([final_boxes, index_vals], 0)\n",
    "        \n",
    "        batch_boxes[n] = final_boxes\n",
    "        \n",
    "    return batch_boxes\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_map(boxes_dict, iou_threshold=0.5):\n",
    "#     import pdb; pdb.set_trace()\n",
    "    v = Variable(torch.zeros(1))\n",
    "    if torch.cuda.is_available():\n",
    "        v = v.cuda()\n",
    "    \n",
    "    if (len(boxes_dict['ground_truth'].size())==0) | (len(boxes_dict['prediction'].size())==0):\n",
    "        return v\n",
    "\n",
    "    gt = boxes_dict['ground_truth']\n",
    "    pr = boxes_dict['prediction']\n",
    "\n",
    "    gt_matched = Variable(-torch.ones(gt.size(0)))\n",
    "    pr_matched = Variable(-torch.ones(pr.size(0)))\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        gt_matched = gt_matched.cuda()\n",
    "        pr_matched = pr_matched.cuda()\n",
    "            \n",
    "    for i in range(len(pr)):\n",
    "        b = pr[i]\n",
    "        ious = bbox_overlap_iou(b[:4].view(1, 4), gt, True)\n",
    "        matched_scores = (gt_matched == -1).float() * (ious[0]>iou_threshold).float() * ious[0]\n",
    "        if torch.sum(matched_scores).data[0] > 0:\n",
    "            gt_idx = torch.max(matched_scores, 0)[1]\n",
    "            gt_matched[gt_idx] = i\n",
    "            pr_matched[i] = gt_idx\n",
    "        \n",
    "    tp = (pr_matched != -1).float()\n",
    "    fp = (pr_matched == -1).float()\n",
    "    tp_cumsum = torch.cumsum(tp, 0)\n",
    "    fp_cumsum = torch.cumsum(fp, 0)\n",
    "    n_corrects = tp_cumsum * tp\n",
    "    total = tp_cumsum + fp_cumsum\n",
    "    precision = n_corrects / total\n",
    "    for i in range(precision.size(0)):\n",
    "        precision[i] = torch.max(precision[i:])\n",
    "\n",
    "    average_precision = torch.sum(precision) / len(gt)\n",
    "    return average_precision\n",
    "    \n",
    "    \n",
    "def evaluation(ground_truths, nms_output, n_truths, iou_thresh):\n",
    "#     import pdb; pdb.set_trace()\n",
    "    N = ground_truths.size(0)\n",
    "    \n",
    "    mean_avg_precision = Variable(torch.FloatTensor([0]))\n",
    "    if torch.cuda.is_available():\n",
    "        mean_avg_precision = mean_avg_precision.cuda()\n",
    "\n",
    "    for batch in range(int(N)):\n",
    "        category_map = defaultdict(lambda: defaultdict(lambda: torch.FloatTensor()))\n",
    "        \n",
    "        if n_truths[batch] == 0:\n",
    "            continue\n",
    "\n",
    "        ground_truth = ground_truths[batch, :n_truths[batch]]\n",
    "        for gt in ground_truth:\n",
    "            gt_class = gt[0].int().data[0]\n",
    "            t1 = category_map[gt_class]['ground_truth']\n",
    "            if len(t1.size()) == 0:\n",
    "                t1 = gt[1:].unsqueeze(0)\n",
    "            else:\n",
    "                t1 = torch.cat([t1, gt[1:].unsqueeze(0)], 0)\n",
    "            category_map[gt_class]['ground_truth'] = t1\n",
    "            \n",
    "        nms_boxes = nms_output[batch]\n",
    "        if len(nms_boxes.size()) == 0:\n",
    "            continue\n",
    "\n",
    "        for box in nms_boxes:\n",
    "            class_id = (torch.max(box[5:], 0)[1]).int().data[0]\n",
    "            t2 = category_map[class_id]['prediction']\n",
    "            if len(t2.size()) == 0:\n",
    "                t2 = box[:5].unsqueeze(0)\n",
    "            else:\n",
    "                t2 = torch.cat([t2, box[:5].unsqueeze(0)], 0)\n",
    "            category_map[class_id]['prediction'] = t2\n",
    "        cat_ids = category_map.keys()\n",
    "#         return category_map\n",
    "        mean_avg_precision += torch.mean(torch.cat([calc_map(category_map[cat_id], iou_thresh) for cat_id in cat_ids], 0 ))\n",
    "    return mean_avg_precision/N\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_map(output, labels, n_true, iou_thresh):\n",
    "    nms_output = get_nms_boxes(output, 0.24, 0.3)\n",
    "    mean_avg_prec = evaluation(labels, nms_output, n_true.numpy(), iou_thresh)\n",
    "    return mean_avg_prec\n",
    "\n",
    "def train(model, train_data, opt, iou_thresh):\n",
    "    train_images = Variable(train_data[\"image\"], requires_grad=True).cuda().float()\n",
    "    train_labels = Variable(train_data[\"bboxes\"], requires_grad=False).cuda().float()\n",
    "    train_n_true = train_data[\"n_true\"]\n",
    "    opt.zero_grad()\n",
    "    train_output = model(train_images)\n",
    "    loss = Yolov2Loss(train_output, train_labels, train_n_true.numpy())\n",
    "    loss.backward()\n",
    "    opt.step()\n",
    "    train_map = get_map(train_output, train_labels, train_n_true, iou_thresh)\n",
    "    return loss, train_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, test_data, iou_thresh):\n",
    "    test_images = Variable(test_data[\"image\"]).cuda().float()\n",
    "    test_labels = Variable(test_data[\"bboxes\"]).cuda().float()\n",
    "    test_n_true = test_data[\"n_true\"]\n",
    "\n",
    "    test_output = model(test_images)\n",
    "    test_loss = Yolov2Loss(test_output, test_labels, test_n_true.numpy())\n",
    "    test_map = get_map(test_output, test_labels, test_n_true, iou_thresh)\n",
    "    return test_loss, test_map\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boundary_box(image_dict):\n",
    "    \"\"\"Show image with landmarks\"\"\"\n",
    "    image = image_dict['image']\n",
    "    bboxes = image_dict['bboxes']\n",
    "    plt.imshow(image)\n",
    "    for bbox in bboxes:\n",
    "        xmin = bbox[1]\n",
    "        ymin = bbox[2]\n",
    "        xmax = bbox[3]\n",
    "        ymax = bbox[4]\n",
    "        plt.plot((xmin, xmin), (ymin, ymax), 'g')\n",
    "        plt.plot((xmin, xmax), (ymin, ymin), 'g')\n",
    "        plt.plot((xmax, xmax), (ymin, ymax), 'g')\n",
    "        plt.plot((xmin, xmax), (ymax, ymax), 'g')\n",
    "\n",
    "def draw_boundary_box_fraction(image_dict):\n",
    "    \"\"\"Show image with landmarks\"\"\"\n",
    "    image = image_dict['image']\n",
    "    height, width, channels = image.shape\n",
    "    bboxes = image_dict['bboxes']\n",
    "    plt.imshow(image)\n",
    "    for bbox in bboxes:\n",
    "        x = bbox[1] * width\n",
    "        y = bbox[2] * height\n",
    "        w = bbox[3] * width\n",
    "        h = bbox[4] * height\n",
    "        xmin = max(0, int(x - w*0.5))\n",
    "        ymin = max(0, int(y - h*0.5))\n",
    "        xmax = min(int(x + w*0.5), width)\n",
    "        ymax = min(int(y + h*0.5), height)\n",
    "        plt.plot((xmin, xmin), (ymin, ymax), 'g')\n",
    "        plt.plot((xmin, xmax), (ymin, ymin), 'g')\n",
    "        plt.plot((xmax, xmax), (ymin, ymax), 'g')\n",
    "        plt.plot((xmin, xmax), (ymax, ymax), 'g')\n",
    "\n",
    "def draw_bbox_torch(img_dict):\n",
    "    image = np.transpose(np.array(img_dict['image'].numpy()*255, np.uint8), (1, 2, 0))\n",
    "    bboxes = img_dict['bboxes'].numpy()\n",
    "    n_true = np.sum(bboxes[:, 0]!=-1)\n",
    "    bboxes = bboxes[:n_true]\n",
    "    draw_boundary_box_fraction({\"image\": image, 'bboxes': bboxes})\n",
    "\n",
    "def draw_bbox_nms(torch_img, nms_output):\n",
    "    image = np.transpose(np.array(torch_img.data.numpy()*255, np.uint8), (1, 2, 0))\n",
    "    bboxes = nms_output[:, :4].data.numpy()\n",
    "    bboxes = np.concatenate([np.zeros(len(bboxes)).reshape(len(bboxes), 1), bboxes], 1)\n",
    "    print (bboxes)\n",
    "    draw_boundary_box_fraction({\"image\": image, 'bboxes': bboxes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grad_var(layers):\n",
    "    params_grad = []\n",
    "    for layer in layers:\n",
    "        for param in layer.parameters():\n",
    "            if param.requires_grad:\n",
    "                params_grad.append(param)\n",
    "    return params_grad\n",
    "\n",
    "def get_optimizer(model, lrs, idxs=[]):\n",
    "    childs = list(model.children())\n",
    "    \n",
    "    if len(idxs)==0:\n",
    "        params = get_grad_var(childs)\n",
    "        opt = torch.optim.Adam(params, lr = lrs[0])\n",
    "        return opt\n",
    "\n",
    "    layer_groups = []\n",
    "    last_idx = 0\n",
    "    for idx in idxs:\n",
    "        layer_groups.append(childs[last_idx:idx])\n",
    "        last_idx = idx\n",
    "    \n",
    "    opt_params = zip(layer_groups, lrs)\n",
    "    opt = torch.optim.Adam([{'params': get_grad_var(p[0]), 'lr': p[1]} for p in opt_params])\n",
    "    return opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_data(batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'DataLoader' object does not support indexing",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-e2ab3ea573f3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'DataLoader' object does not support indexing"
     ]
    }
   ],
   "source": [
    "train_loader[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lr():\n",
    "#     import pdb; pdb.set_trace()\n",
    "#     from IPython.core.debugger import Tracer; Tracer()()\n",
    "    train_loader, test_loader = get_data(batch_size=batch_size)\n",
    "    model = get_model()\n",
    "    start_lr = 0.00001\n",
    "    end_lr = 10\n",
    "    \n",
    "    opt = get_optimizer(model, [start_lr])\n",
    "    \n",
    "    sched = torch.optim.lr_scheduler.ExponentialLR(opt, ((end_lr/start_lr)** (1./meta['iterations_per_epoch'])))\n",
    "    \n",
    "    losses = []\n",
    "    lrs = []\n",
    "    best_loss = 10**10\n",
    "    meta['iteration'] = 0\n",
    "    from IPython.core.debugger import Tracer; Tracer()()\n",
    "    for i, train_data in enumerate(train_loader):\n",
    "        if train_data[\"image\"].size(0) != batch_size:\n",
    "            break\n",
    "\n",
    "        sched.step()\n",
    "        loss, acc_map = train(model, train_data, opt, 0.3)\n",
    "        loss_val = loss.data[0]\n",
    "        \n",
    "        lrs.append(sched.get_lr()[0])\n",
    "        losses.append(loss_val)\n",
    "        if loss_val < best_loss:\n",
    "            best_loss = loss_val\n",
    "        \n",
    "        if loss_val > 4*best_loss:\n",
    "            break\n",
    "        \n",
    "        if meta['iteration']%20 == 0:\n",
    "            print (\"iteration {0} loss {1} map {2}\".format(meta['iteration'], loss_val, acc_map))\n",
    "        meta['iteration'] += batch_size\n",
    "        \n",
    "    return lrs, losses, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "meta = defaultdict()\n",
    "meta['anchors'] = 5\n",
    "meta['classes'] = 20\n",
    "meta['batch_size'] = batch_size\n",
    "meta['threshold'] = 0.6\n",
    "meta['anchor_bias'] = np.array([1.08,1.19,  3.42,4.41,  6.63,11.38,  9.42,5.11,  16.62,10.52])\n",
    "meta['scale_no_obj'] = 1\n",
    "meta['scale_coords'] = 1\n",
    "meta['scale_class'] = 1\n",
    "meta['scale_obj']  = 5\n",
    "meta['iteration'] = 0 \n",
    "meta['train_samples'] = len(voc_2007) + sum(voc_2012[\"train\"]==1)\n",
    "meta['iterations_per_epoch'] = meta['train_samples']/batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:17: DeprecationWarning: `Tracer` is deprecated since version 5.1, directly use `IPython.core.debugger.Pdb.set_trace()`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-43-698c99b41ed7>\u001b[0m(18)\u001b[0;36mfind_lr\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     16 \u001b[0;31m    \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iteration'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m    \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebugger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTracer\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mTracer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 18 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     19 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     20 \u001b[0;31m            \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> len(train_loader)\n",
      "518\n",
      "ipdb> train_loader[0]\n",
      "*** TypeError: 'DataLoader' object does not support indexing\n",
      "ipdb> a = next(train_loader)\n",
      "ipdb> a\n",
      "ipdb> type(a)\n",
      "*** NameError: name 'a' is not defined\n",
      "ipdb> for i, train_data in enumerate(train_loader):\n",
      "*** SyntaxError: unexpected EOF while parsing\n",
      "ipdb> n\n",
      "TypeError: function takes exactly 5 arguments (1 given)\n",
      "> \u001b[0;32m<ipython-input-43-698c99b41ed7>\u001b[0m(18)\u001b[0;36mfind_lr\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     16 \u001b[0;31m    \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iteration'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m    \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebugger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTracer\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mTracer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 18 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     19 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     20 \u001b[0;31m            \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> i\n",
      "*** NameError: name 'i' is not defined\n",
      "ipdb> n\n",
      "--Return--\n",
      "None\n",
      "> \u001b[0;32m<ipython-input-43-698c99b41ed7>\u001b[0m(18)\u001b[0;36mfind_lr\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     16 \u001b[0;31m    \u001b[0mmeta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iteration'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     17 \u001b[0;31m    \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebugger\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTracer\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mTracer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 18 \u001b[0;31m    \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     19 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     20 \u001b[0;31m            \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> n\n",
      "TypeError: function takes exactly 5 arguments (1 given)\n",
      "None\n",
      "> \u001b[0;32m<ipython-input-45-a5774f6fb915>\u001b[0m(1)\u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m----> 1 \u001b[0;31m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      2 \u001b[0;31m\u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m250\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b-'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> exit\n",
      "Exiting Debugger.\n"
     ]
    }
   ],
   "source": [
    "lrs, losses, model = find_lr()\n",
    "plt.plot(lrs[:250], losses[:250], 'b-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fb4b73b82e8>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Yolov2(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batchnorm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batchnorm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batchnorm3): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (batchnorm4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batchnorm5): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batchnorm6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv7): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (batchnorm7): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv8): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batchnorm8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv9): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batchnorm9): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv10): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (batchnorm10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv11): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batchnorm11): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv12): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (batchnorm12): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv13): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batchnorm13): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv14): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batchnorm14): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv15): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (batchnorm15): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv16): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batchnorm16): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv17): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "  (batchnorm17): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv18): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batchnorm18): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv19): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batchnorm19): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv20): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batchnorm20): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv21): Conv2d(3072, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "  (batchnorm21): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv22): Conv2d(1024, 125, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_lr = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineAnnealingLR(_LRScheduler):\n",
    "\n",
    "    def __init__(self, optimizer, T_max, eta_min=0, last_epoch=-1):\n",
    "        self.T_max = T_max\n",
    "        self.eta_min = eta_min\n",
    "        super(CosineAnnealingLR, self).__init__(optimizer, last_epoch)\n",
    "\n",
    "    def get_lr(self):\n",
    "        return [self.eta_min + (base_lr - self.eta_min) *\n",
    "                (1 + math.cos(math.pi * self.last_epoch / self.T_max)) / 2\n",
    "                for base_lr in self.base_lrs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_last_layers(model, lr_est, n_cycles=1, epochs_per_cycle=1, cycle_mult=1):\n",
    "#     sample_size = 1920\n",
    "    train_loader, test_loader = get_data(batch_size=batch_size)\n",
    "\n",
    "    metrics = {'train':{'loss':[], 'acc': []}, 'test': {'loss': [], 'acc': []}}\n",
    "    # No Layer Groups\n",
    "    opt = get_optimizer(model, [lr_est])\n",
    "    \n",
    "    meta['iteration'] = 0\n",
    "    for cycle in range(n_cycles):\n",
    "                \n",
    "        # resetting the lr to original\n",
    "        param_groups = opt.param_groups\n",
    "        for param_group in param_groups:\n",
    "            param_group['lr'] = lr_est\n",
    "\n",
    "        cycle_len = meta['iterations_per_epoch'] * epochs_per_cycle\n",
    "        sched = CosineAnnealingLR(opt, cycle_len)\n",
    "\n",
    "        for epoch in range(epochs_per_cycle):\n",
    "            \n",
    "            for i, train_data in enumerate(train_loader):\n",
    "                if train_data[\"image\"].size(0) != batch_size:\n",
    "                    break\n",
    "                \n",
    "                sched.step()\n",
    "                loss, acc_map = train(model, train_data, opt, 0.3)\n",
    "                loss_val = loss.data[0]\n",
    "                acc_val = acc_map.data[0]\n",
    "                metrics['train']['loss'].append(loss_val)\n",
    "                metrics['train']['acc'].append(acc_val)\n",
    "                \n",
    "                meta['iteration'] += batch_size\n",
    "                \n",
    "                if meta['iteration']%(4*batch_size) == 0:\n",
    "                    total_test_loss = []\n",
    "                    total_test_acc = []\n",
    "                    for i, test_data in enumerate(test_loader):\n",
    "                        if test_data[\"image\"].size(0) != batch_size:\n",
    "                            break\n",
    "                        \n",
    "                        test_loss, test_acc = validate(model, test_data, 0.3)\n",
    "                        total_test_loss.append(test_loss.data[0])\n",
    "                        total_test_acc.append(test_acc.data[0])\n",
    "                    \n",
    "                    test_loss = np.mean(total_test_loss)\n",
    "                    test_acc = np.mean(total_test_acc)\n",
    "                    \n",
    "                    metrics['test']['loss'].append(test_loss)\n",
    "                    metrics['test']['acc'].append(test_acc)\n",
    "                    print (\"Iteration {0} Train Loss {1} Acc {2} Test Loss {3} Acc {4}\".format(\n",
    "                        meta['iteration'], loss_val, acc_val, test_loss, test_acc))\n",
    "                    \n",
    "                        \n",
    "        epochs_per_cycle *= cycle_mult\n",
    "    \n",
    "    return model, metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = train_last_layers(model, start_lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, open(\"model_2\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(open(\"model\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader, test_loader = get_data(batch_size=batch_size)\n",
    "for i, test_data in enumerate(test_loader):\n",
    "    test_images = Variable(test_data[\"image\"], requires_grad=True).cuda().float()\n",
    "    test_labels = Variable(test_data[\"bboxes\"], requires_grad=False).cuda().float()\n",
    "    test_n_true = test_data[\"n_true\"]\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output = model(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nnms = get_nms_boxes(test_output, 0.24, 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bbox_torch({\"image\": test_images[0].cpu().data, \"bboxes\": test_labels[0].cpu().data})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "draw_bbox_nms(test_images[0].cpu(), nnms[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(nnms[0][0][5:], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.children())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.children())[4].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model2.children())[4].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(model.children())[0].weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all_layers(model, lrs, layer_groups, n_cycles=1, epochs_per_cycle=1, cycle_mult=1):\n",
    "    \n",
    "    train_loader, test_loader = get_data()\n",
    "    opt = get_optimizer(model, [lr_est/100, lr_est/10, lr_est], [16, 36, 43])\n",
    "    metrics = {'train':{'loss':[], 'acc': []}, 'test': {'loss': [], 'acc': []}}\n",
    "    # No Layer Groups\n",
    "    opt = get_optimizer(model, [lr_est])\n",
    "    \n",
    "    meta['iteration'] = 0\n",
    "    for cycle in range(n_cycles):\n",
    "                \n",
    "        # resetting the lr to original\n",
    "        param_groups = opt.param_groups\n",
    "        for param_group in param_groups:\n",
    "            param_group['lr'] = lr_est\n",
    "\n",
    "        cycle_len = meta['iterations_per_epoch'] * epochs_per_cycle\n",
    "        sched = CosineAnnealingLR(opt, cycle_len)\n",
    "\n",
    "        for epoch in range(epochs_per_cycle):\n",
    "            \n",
    "            for i, train_data in enumerate(train_loader):\n",
    "                if train_data[\"image\"].size(0) != batch_size:\n",
    "                    break\n",
    "                \n",
    "                sched.step()\n",
    "                loss, acc_map = train(model, train_data, opt)\n",
    "                loss_val = loss.data[0]\n",
    "                acc_val = acc_map.data[0]\n",
    "                metrics['train']['loss'].append(loss_val)\n",
    "                metrics['train']['acc'].append(acc_val)\n",
    "                \n",
    "                meta['iteration'] += batch_size\n",
    "                \n",
    "                if meta['iteration']%100 == 0:\n",
    "                    total_test_loss = []\n",
    "                    total_test_acc = []\n",
    "                    for i, test_data in enumerate(test_loader):\n",
    "                        if test_data[\"image\"].size(0) != batch_size:\n",
    "                            break\n",
    "                        \n",
    "                        test_loss, test_acc = validate(model, test_data)\n",
    "                        total_test_loss.append(test_loss.data[0])\n",
    "                        total_test_acc.append(test_acc.data[0])\n",
    "                    \n",
    "                    test_loss = np.mean(total_test_loss)\n",
    "                    test_acc = np.mean(total_test_acc)\n",
    "                    \n",
    "                    metrics['test']['loss'].append(test_loss)\n",
    "                    metrics['test']['acc'].append(test_acc)\n",
    "                    print (\"Iteration {0} Train Loss {1} Acc {2} Test Loss {3} Acc {4}\".format(\n",
    "                        meta['iteration'], loss_val, acc_val, test_loss, test_acc))\n",
    "                    \n",
    "                        \n",
    "        epochs_per_cycle *= cycle_mult\n",
    "    \n",
    "    return model, metrics\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "\n",
    "for epoch in range(epochs):\n",
    "#     import pdb; pdb.set_trace()\n",
    "    for i, train_data in enumerate(train_loader):\n",
    "        if train_data[\"image\"].size(0) != batch_size:\n",
    "            continue\n",
    "        train_images = Variable(train_data[\"image\"], requires_grad=True).cuda().float()\n",
    "        train_labels = Variable(train_data[\"bboxes\"], requires_grad=False).cuda().float()\n",
    "        train_n_true = train_data[\"n_true\"]\n",
    "        \n",
    "        sched.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        updated_lr = current_lr * 1.0223509385032303\n",
    "        print (\"current lr -- updated lr\", current_lr, updated_lr)\n",
    "        optimizer.param_groups[0]['lr'] = updated_lr\n",
    "        train_output = model(train_images)\n",
    "        \n",
    "        try:\n",
    "            loss = Yolov2Loss(train_output, train_labels, train_n_true.numpy())\n",
    "        except Exception as e:\n",
    "            print (iteration, i)\n",
    "            raise e\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_vals.append(updated_lr)\n",
    "        loss_vals.append(loss.data[0])\n",
    "        \n",
    "        iteration += batch_size\n",
    "        \n",
    "        if iteration%2 == 0:\n",
    "            \n",
    "            test_total = 0\n",
    "            test_total_map = torch.cuda.FloatTensor([0])\n",
    "            for j, test_data in enumerate(test_loader):\n",
    "                test_images = Variable(test_data[\"image\"]).cuda().float()\n",
    "                test_labels = Variable(test_data[\"bboxes\"]).cuda().float()\n",
    "                test_n_true = test_data[\"n_true\"]\n",
    "                \n",
    "                test_output = model(test_images)\n",
    "                test_nms = get_nms_detections(test_output, 0.4, 0.4)\n",
    "                \n",
    "                test_map = evaluation(test_labels, test_nms, test_n_true.numpy())\n",
    "                test_total_map += test_map.data\n",
    "                test_total += 1\n",
    "            test_avg_map = test_total_map / test_total\n",
    "            \n",
    "            print (\"Iteration {} loss {} accuracy {}\".format(iteration, loss.data[0], test_avg_map))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, b in enumerate(train_loader):\n",
    "    img = b['image']\n",
    "    bboxes = b['bboxes']\n",
    "    break\n",
    "\n",
    "draw_bbox_torch({\"image\": img[0], \"bboxes\":bboxes[0]})\n",
    "\n",
    "out = model(Variable(img.float().cuda()))\n",
    "\n",
    "iteration = 1\n",
    "loss = Yolov2Loss(out, Variable(bboxes).cuda().float(), b['n_true'].numpy())\n",
    "\n",
    "t = get_nms_detections(out)\n",
    "\n",
    "mean_ap = evaluation(Variable(bboxes).float().cuda(), t, b['n_true'].numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
